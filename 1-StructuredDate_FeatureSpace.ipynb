{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oynt6jLtspRM"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.12"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "6AWcwMzIs_Fy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "header=['Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology','Horizontal_Distance_To_Roadways'\n",
        "        ,'Hillshade_9am','Hillshade_Noon','Hillshade_3pm','Horizontal_Distance_To_Fire_Points'\n",
        "        ,'Wilderness_Area1','Wilderness_Area2','Wilderness_Area3','Wilderness_Area4'\n",
        "        ,'Soil_Type1', 'Soil_Type2','Soil_Type3','Soil_Type4','Soil_Type5','Soil_Type6','Soil_Type7','Soil_Type8'\n",
        "        ,'Soil_Type9','Soil_Type10','Soil_Type11','Soil_Type12','Soil_Type13','Soil_Type14','Soil_Type15','Soil_Type16'\n",
        "        ,'Soil_Type17','Soil_Type18','Soil_Type19','Soil_Type20','Soil_Type21','Soil_Type22','Soil_Type23','Soil_Type24'\n",
        "        ,'Soil_Type25','Soil_Type26','Soil_Type27','Soil_Type28','Soil_Type29','Soil_Type30','Soil_Type31','Soil_Type32'\n",
        "        ,'Soil_Type33','Soil_Type34','Soil_Type35','Soil_Type36','Soil_Type37','Soil_Type38','Soil_Type39','Soil_Type40'\n",
        "        ,'Cover_Type']"
      ],
      "metadata": {
        "id": "ncXqnCqRtR6q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz',compression='gzip',names=header)"
      ],
      "metadata": {
        "id": "TqkylhjdtSJT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe=dataframe.iloc[:10000]"
      ],
      "metadata": {
        "id": "qPgpxagG1L_t"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
        "train_dataframe = dataframe.drop(val_dataframe.index)\n",
        "\n",
        "print(\n",
        "    \"Using %d samples for training and %d for validation\"\n",
        "    % (len(train_dataframe), len(val_dataframe))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPjut2j8tSTT",
        "outputId": "5e2d6743-987b-4244-c837-44d992912bed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 8000 samples for training and 2000 for validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "def dataframe_to_dataset(dataframe):\n",
        "    dataframe = dataframe.copy()\n",
        "    labels = dataframe.pop(\"Cover_Type\")\n",
        "    labels=to_categorical(labels)\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "    return ds\n",
        "\n",
        "\n",
        "train_ds = dataframe_to_dataset(train_dataframe)\n",
        "val_ds = dataframe_to_dataset(val_dataframe)"
      ],
      "metadata": {
        "id": "C2v4rvcutdGK"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.batch(32)\n",
        "val_ds = val_ds.batch(32)"
      ],
      "metadata": {
        "id": "-xbm8i9htdOK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import FeatureSpace\n",
        "\n",
        "feature_space = FeatureSpace(\n",
        "    features={\n",
        "        # Categorical features encoded as integers\n",
        "        \"Slope\": \"integer_categorical\",\n",
        "        \"Wilderness_Area1\":\"integer_categorical\",\n",
        "        \"Wilderness_Area2\":\"integer_categorical\",\n",
        "        \"Wilderness_Area3\":\"integer_categorical\",\n",
        "        \"Wilderness_Area4\":\"integer_categorical\",\n",
        "        \"Soil_Type1\": \"integer_categorical\",\n",
        "        \"Soil_Type2\": \"integer_categorical\",\n",
        "        \"Soil_Type3\": \"integer_categorical\",\n",
        "        \"Soil_Type4\": \"integer_categorical\",\n",
        "        \"Soil_Type5\": \"integer_categorical\",\n",
        "        \"Soil_Type6\": \"integer_categorical\",\n",
        "        \"Soil_Type7\": \"integer_categorical\",\n",
        "        \"Soil_Type8\": \"integer_categorical\",\n",
        "        \"Soil_Type9\": \"integer_categorical\",\n",
        "        \"Soil_Type10\": \"integer_categorical\",\n",
        "        \"Soil_Type11\": \"integer_categorical\",\n",
        "        \"Soil_Type12\": \"integer_categorical\",\n",
        "        \"Soil_Type13\": \"integer_categorical\",\n",
        "        \"Soil_Type14\": \"integer_categorical\",\n",
        "        \"Soil_Type15\": \"integer_categorical\",\n",
        "        \"Soil_Type16\": \"integer_categorical\",\n",
        "        \"Soil_Type17\": \"integer_categorical\",\n",
        "        \"Soil_Type18\": \"integer_categorical\",\n",
        "        \"Soil_Type19\": \"integer_categorical\",\n",
        "        \"Soil_Type20\": \"integer_categorical\",\n",
        "        \"Soil_Type21\": \"integer_categorical\",\n",
        "        \"Soil_Type22\": \"integer_categorical\",\n",
        "        \"Soil_Type23\": \"integer_categorical\",\n",
        "        \"Soil_Type24\": \"integer_categorical\",\n",
        "        \"Soil_Type25\": \"integer_categorical\",\n",
        "        \"Soil_Type26\": \"integer_categorical\",\n",
        "        \"Soil_Type27\": \"integer_categorical\",\n",
        "        \"Soil_Type28\": \"integer_categorical\",\n",
        "        \"Soil_Type29\": \"integer_categorical\",\n",
        "        \"Soil_Type30\": \"integer_categorical\",\n",
        "        \"Soil_Type31\": \"integer_categorical\",\n",
        "        \"Soil_Type32\": \"integer_categorical\",\n",
        "        \"Soil_Type33\": \"integer_categorical\",\n",
        "        \"Soil_Type34\": \"integer_categorical\",\n",
        "        \"Soil_Type35\": \"integer_categorical\",\n",
        "        \"Soil_Type36\": \"integer_categorical\",\n",
        "        \"Soil_Type37\": \"integer_categorical\",\n",
        "        \"Soil_Type38\": \"integer_categorical\",\n",
        "        \"Soil_Type39\": \"integer_categorical\",\n",
        "        \"Soil_Type40\": \"integer_categorical\",\n",
        "\n",
        "        # Numerical features to normalize\n",
        "        \"Elevation\": \"float_normalized\",\n",
        "        \"Aspect\": \"float_normalized\",\n",
        "        \"Horizontal_Distance_To_Hydrology\": \"float_normalized\",\n",
        "        \"Vertical_Distance_To_Hydrology\": \"float_normalized\",\n",
        "        \"Horizontal_Distance_To_Roadways\": \"float_normalized\",\n",
        "        \"Hillshade_9am\": \"float_normalized\",\n",
        "        \"Hillshade_Noon\": \"float_normalized\",\n",
        "        \"Hillshade_3pm\": \"float_normalized\",\n",
        "        \"Horizontal_Distance_To_Fire_Points\": \"float_normalized\",\n",
        "    },\n",
        "    # Our utility will one-hot encode all categorical\n",
        "    # features and concat all features into a single\n",
        "    # vector (one vector per sample).\n",
        "    output_mode=\"concat\",\n",
        ")"
      ],
      "metadata": {
        "id": "Vk5QDk_ytE7z"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_with_no_labels = train_ds.map(lambda x, _: x)\n",
        "feature_space.adapt(train_ds_with_no_labels)"
      ],
      "metadata": {
        "id": "AxJFGmT6tdU6"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, _ in train_ds.take(1):\n",
        "    preprocessed_x = feature_space(x)\n",
        "    print(\"preprocessed_x.shape:\", preprocessed_x.shape)\n",
        "    print(\"preprocessed_x.dtype:\", preprocessed_x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRw3Wmk1uQSM",
        "outputId": "03dd0d30-78b6-4527-fb5e-23f899abb5a9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessed_x.shape: (32, 190)\n",
            "preprocessed_x.dtype: <dtype: 'float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_train_ds = train_ds.map(\n",
        "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "preprocessed_train_ds = preprocessed_train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "preprocessed_val_ds = val_ds.map(\n",
        "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "preprocessed_val_ds = preprocessed_val_ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "Hs_SeuG7uQhI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_inputs = feature_space.get_inputs()\n",
        "encoded_features = feature_space.get_encoded_features()\n",
        "\n",
        "x = keras.layers.Dense(512, activation=\"relu\")(encoded_features)\n",
        "x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
        "x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
        "x = keras.layers.Dropout(0.5)(x)\n",
        "predictions = keras.layers.Dense(8, activation=\"softmax\")(x)\n",
        "\n",
        "training_model = keras.Model(inputs=encoded_features, outputs=predictions)\n",
        "training_model.compile(\n",
        "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "inference_model = keras.Model(inputs=dict_inputs, outputs=predictions)"
      ],
      "metadata": {
        "id": "PmABtMceuQji"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_model.fit(\n",
        "    preprocessed_train_ds, epochs=20, validation_data=preprocessed_val_ds, verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q01SFHKBuXJX",
        "outputId": "f6dec15e-811d-4696-c0c8-96de17c3d79c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "250/250 - 4s - loss: 0.9547 - accuracy: 0.5971 - val_loss: 0.7293 - val_accuracy: 0.6905 - 4s/epoch - 15ms/step\n",
            "Epoch 2/20\n",
            "250/250 - 4s - loss: 0.7412 - accuracy: 0.6870 - val_loss: 0.6335 - val_accuracy: 0.7360 - 4s/epoch - 15ms/step\n",
            "Epoch 3/20\n",
            "250/250 - 3s - loss: 0.6905 - accuracy: 0.7056 - val_loss: 0.6243 - val_accuracy: 0.7315 - 3s/epoch - 13ms/step\n",
            "Epoch 4/20\n",
            "250/250 - 3s - loss: 0.6270 - accuracy: 0.7340 - val_loss: 0.5845 - val_accuracy: 0.7510 - 3s/epoch - 12ms/step\n",
            "Epoch 5/20\n",
            "250/250 - 4s - loss: 0.5899 - accuracy: 0.7494 - val_loss: 0.5677 - val_accuracy: 0.7525 - 4s/epoch - 16ms/step\n",
            "Epoch 6/20\n",
            "250/250 - 3s - loss: 0.5674 - accuracy: 0.7619 - val_loss: 0.5767 - val_accuracy: 0.7595 - 3s/epoch - 12ms/step\n",
            "Epoch 7/20\n",
            "250/250 - 3s - loss: 0.5381 - accuracy: 0.7820 - val_loss: 0.5558 - val_accuracy: 0.7765 - 3s/epoch - 12ms/step\n",
            "Epoch 8/20\n",
            "250/250 - 4s - loss: 0.5181 - accuracy: 0.7876 - val_loss: 0.5684 - val_accuracy: 0.7610 - 4s/epoch - 18ms/step\n",
            "Epoch 9/20\n",
            "250/250 - 3s - loss: 0.5123 - accuracy: 0.7935 - val_loss: 0.5595 - val_accuracy: 0.7710 - 3s/epoch - 12ms/step\n",
            "Epoch 10/20\n",
            "250/250 - 3s - loss: 0.4840 - accuracy: 0.7997 - val_loss: 0.5159 - val_accuracy: 0.7950 - 3s/epoch - 12ms/step\n",
            "Epoch 11/20\n",
            "250/250 - 5s - loss: 0.4544 - accuracy: 0.8094 - val_loss: 0.5599 - val_accuracy: 0.7650 - 5s/epoch - 18ms/step\n",
            "Epoch 12/20\n",
            "250/250 - 3s - loss: 0.4320 - accuracy: 0.8236 - val_loss: 0.5338 - val_accuracy: 0.7770 - 3s/epoch - 12ms/step\n",
            "Epoch 13/20\n",
            "250/250 - 3s - loss: 0.4215 - accuracy: 0.8271 - val_loss: 0.5845 - val_accuracy: 0.7805 - 3s/epoch - 13ms/step\n",
            "Epoch 14/20\n",
            "250/250 - 4s - loss: 0.3853 - accuracy: 0.8462 - val_loss: 0.5264 - val_accuracy: 0.7940 - 4s/epoch - 18ms/step\n",
            "Epoch 15/20\n",
            "250/250 - 3s - loss: 0.3730 - accuracy: 0.8484 - val_loss: 0.5537 - val_accuracy: 0.7770 - 3s/epoch - 12ms/step\n",
            "Epoch 16/20\n",
            "250/250 - 3s - loss: 0.3591 - accuracy: 0.8540 - val_loss: 0.6352 - val_accuracy: 0.7610 - 3s/epoch - 12ms/step\n",
            "Epoch 17/20\n",
            "250/250 - 5s - loss: 0.3474 - accuracy: 0.8568 - val_loss: 0.5683 - val_accuracy: 0.7870 - 5s/epoch - 18ms/step\n",
            "Epoch 18/20\n",
            "250/250 - 3s - loss: 0.3254 - accuracy: 0.8665 - val_loss: 0.5718 - val_accuracy: 0.7980 - 3s/epoch - 12ms/step\n",
            "Epoch 19/20\n",
            "250/250 - 3s - loss: 0.3158 - accuracy: 0.8700 - val_loss: 0.5569 - val_accuracy: 0.8025 - 3s/epoch - 12ms/step\n",
            "Epoch 20/20\n",
            "250/250 - 3s - loss: 0.2941 - accuracy: 0.8776 - val_loss: 0.5647 - val_accuracy: 0.8075 - 3s/epoch - 14ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7883a68e20>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gg05rlCtuXUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8KMD-BKJuQm-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}