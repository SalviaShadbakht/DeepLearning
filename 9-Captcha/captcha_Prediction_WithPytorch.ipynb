{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob \n",
        "import pandas as pd\n",
        "import string\n",
        "import collections\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Path of dataset\n",
        "path = './data/'\n",
        "# The function for creating the dataframe from dataset\n",
        "def Load_dataset():\n",
        "    # Open the dataset\n",
        "    data = glob.glob(os.path.join('./data/', '*.png'))\n",
        "    # try to encoding labels with ascii letters and save them in a Dataframe\n",
        "    all_letters = string.ascii_uppercase + string.digits+string.ascii_lowercase\n",
        "    mapping={}\n",
        "    mapping_inv = {}\n",
        "    i = 1\n",
        "    for x in all_letters:\n",
        "        mapping[x] = i\n",
        "        mapping_inv[i] = x\n",
        "        i += 1\n",
        "    # The number of class\n",
        "    num_class = len(mapping)\n",
        "    print(num_class)\n",
        "    # make a dataset\n",
        "    images = [] # list for saving images\n",
        "    labels = [] # list for saving labels\n",
        "    # create a dictionary\n",
        "    datas = collections.defaultdict(list)\n",
        "    for d in data:\n",
        "        x = d.split('/')[-1]\n",
        "        datas['image'].append(x)\n",
        "        datas['label'].append([mapping[i] for i in x.split('.')[0]])\n",
        "    # Save dictionary to DataFrame\n",
        "    df = pd.DataFrame(datas)\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "# create a captchadatset \n",
        "class CaptchaDataset:\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        # torchvision.transforms to Composes several transforms together\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        data = self.df.iloc[idx]\n",
        "        # Use PIL Library: ‘L’ convert function converts the image from it’s regular RGB colors to simple black and white (gray-scale).\n",
        "        image = Image.open(os.path.join(path, data['image'])).convert('L')\n",
        "        # Convert labels to torch\n",
        "        label = torch.tensor(data['label'], dtype=torch.int32)\n",
        "        # print(image)\n",
        "        # print(label)\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        return image, label\n",
        "\n",
        " \n",
        "# Create Bidirectional \n",
        "class Bidirectional(nn.Module):\n",
        "    def __init__(self, inp, hidden, out, lstm=True):\n",
        "        super(Bidirectional, self).__init__()\n",
        "        if lstm:\n",
        "            self.rnn = nn.LSTM(inp, hidden, bidirectional=True)\n",
        "        else:\n",
        "            self.rnn = nn.GRU(inp, hidden, bidirectional=True)\n",
        "        self.embedding = nn.Linear(hidden*2, out)\n",
        "    def forward(self, X):\n",
        "        recurrent, _ = self.rnn(X)\n",
        "        out = self.embedding(recurrent)     \n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "# CRNN model for Captcha\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, in_channels, output):\n",
        "        super(CRNN, self).__init__()\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, 256, 9, stride=1, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.MaxPool2d(3, 3),\n",
        "                nn.Conv2d(256, 256, (4, 3), stride=1, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(256))\n",
        "        \n",
        "        self.linear = nn.Linear(5888, 256)\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.rnn = Bidirectional(256, 1024, output+1)\n",
        "\n",
        "    def forward(self, X, y=None, criterion = None):\n",
        "        out = self.cnn(X)\n",
        "        N, C, w, h = out.size()\n",
        "        out = out.view(N, -1, h)\n",
        "        # It returns a view of the input tensor with its dimension permuted. \n",
        "        out = out.permute(0, 2, 1)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        out = out.permute(1, 0, 2)\n",
        "        out = self.rnn(out)\n",
        "            \n",
        "        if y is not None:\n",
        "            T = out.size(0)\n",
        "            N = out.size(1)\n",
        "\n",
        "            #Creates a tensor of size,size filled with fill_value,and can select dtype\n",
        "            input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.int32)\n",
        "            target_lengths = torch.full(size=(N,), fill_value=5, dtype=torch.int32)\n",
        "        \n",
        "            loss = criterion(out, y, input_lengths, target_lengths)\n",
        "            \n",
        "            return out, loss\n",
        "        \n",
        "        return out, None\n",
        "    \n",
        "    def _ConvLayer(self, inp, out, kernel, stride, padding, bn=False):\n",
        "        if bn:\n",
        "            conv = [\n",
        "                nn.Conv2d(inp, out, kernel, stride=stride, padding=padding),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(out)\n",
        "            ]\n",
        "        else:\n",
        "            conv = [\n",
        "                nn.Conv2d(inp, out, kernel, stride=stride, padding=padding),\n",
        "                nn.ReLU()\n",
        "            ]\n",
        "        return nn.Sequential(*conv)\n",
        "\n",
        "\n",
        "   \n",
        "\n",
        "# Train the model\n",
        "def final():\n",
        "    # Load dataset\n",
        "    df=Load_dataset()\n",
        "    df_train, df_test = train_test_split(df, test_size=0.2, shuffle=True)\n",
        "    # Composes several transforms together\n",
        "    transform = T.Compose([\n",
        "    T.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Load data as CaptchaDataset\n",
        "    train_data = CaptchaDataset(df_train, transform)\n",
        "    test_data = CaptchaDataset(df_test, transform)\n",
        "\n",
        "    # Pytorch’s DataLoader is responsible for managing batches\n",
        "    # And use train_loader in each epochs\n",
        "    train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=8)\n",
        "\n",
        "    # Create Device to check CPU or GPU\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    # The output of model is number of classes that is equal to 62\n",
        "    model = CRNN(in_channels=1, output=62).to(device)\n",
        "    print(model)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    # Add CTCLoss at each steps\n",
        "    # CTCLoss:Calculates loss between a continuous (unsegmented) time series and a target sequence\n",
        "    criterion = nn.CTCLoss()\n",
        "    \n",
        "\n",
        "    # Within each epoch run the subsets of data = batch sizes\n",
        "    hist_loss = []\n",
        "    for epoch in range(100):\n",
        "            model.train()\n",
        "            # tqdm is used to create a smart progress bar for the loops\n",
        "            tk = tqdm(train_loader, total=len(train_loader))\n",
        "            for data, target in tk:\n",
        "                data = data.to(device=device)\n",
        "                target = target.to(device=device)\n",
        "\n",
        "                optimizer.zero_grad() # Clearing all previous gradients, setting to zero \n",
        "                out, loss = model(data, target, criterion=criterion) # Loss Computation\n",
        "                loss.backward() # Back Propagation\n",
        "                optimizer.step() # Updating the parameters\n",
        "                tk.set_postfix({'Epoch':epoch+1, 'Loss' : loss.item()})\n",
        "    print('Last iteration loss value: '+str(loss.item()))\n",
        "final()   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S6gLNf2NQlw",
        "outputId": "dd62d12a-f6bd-4099-d6d5-dd02d653f5ff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n",
            "CRNN(\n",
            "  (cnn): Sequential(\n",
            "    (0): Conv2d(1, 256, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(256, 256, kernel_size=(4, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (linear): Linear(in_features=5888, out_features=256, bias=True)\n",
            "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (rnn): Bidirectional(\n",
            "    (rnn): LSTM(256, 1024, bidirectional=True)\n",
            "    (embedding): Linear(in_features=2048, out_features=63, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 54/54 [00:07<00:00,  7.57it/s, Epoch=1, Loss=3.82]\n",
            "100%|██████████| 54/54 [00:07<00:00,  7.43it/s, Epoch=2, Loss=4.47]\n",
            "100%|██████████| 54/54 [00:07<00:00,  7.40it/s, Epoch=3, Loss=4.48]\n",
            "100%|██████████| 54/54 [00:07<00:00,  7.48it/s, Epoch=4, Loss=4.46]\n",
            "100%|██████████| 54/54 [00:07<00:00,  7.66it/s, Epoch=5, Loss=4.49]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.77it/s, Epoch=6, Loss=4.5]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.81it/s, Epoch=7, Loss=4.51]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.97it/s, Epoch=8, Loss=4.44]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.91it/s, Epoch=9, Loss=4.49]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.98it/s, Epoch=10, Loss=4.45]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.85it/s, Epoch=11, Loss=4.46]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.86it/s, Epoch=12, Loss=4.49]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.74it/s, Epoch=13, Loss=4.43]\n",
            "100%|██████████| 54/54 [00:07<00:00,  7.71it/s, Epoch=14, Loss=4.42]\n",
            "100%|██████████| 54/54 [00:07<00:00,  7.70it/s, Epoch=15, Loss=4.48]\n",
            "100%|██████████| 54/54 [00:07<00:00,  7.64it/s, Epoch=16, Loss=4.49]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.74it/s, Epoch=17, Loss=4.44]\n",
            "100%|██████████| 54/54 [00:07<00:00,  7.67it/s, Epoch=18, Loss=4.44]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.81it/s, Epoch=19, Loss=4.35]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.76it/s, Epoch=20, Loss=4.41]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.81it/s, Epoch=21, Loss=4.43]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.83it/s, Epoch=22, Loss=4.45]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.78it/s, Epoch=23, Loss=4.43]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.86it/s, Epoch=24, Loss=4.53]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.74it/s, Epoch=25, Loss=4.47]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.84it/s, Epoch=26, Loss=4.51]\n",
            "100%|██████████| 54/54 [00:07<00:00,  7.71it/s, Epoch=27, Loss=4.42]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.78it/s, Epoch=28, Loss=4.38]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.75it/s, Epoch=29, Loss=4.41]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.72it/s, Epoch=30, Loss=4.44]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.80it/s, Epoch=31, Loss=4.49]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.77it/s, Epoch=32, Loss=4.55]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.85it/s, Epoch=33, Loss=4.5]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.74it/s, Epoch=34, Loss=4.59]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.82it/s, Epoch=35, Loss=4.57]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.77it/s, Epoch=36, Loss=4.41]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.79it/s, Epoch=37, Loss=4.21]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.85it/s, Epoch=38, Loss=4.28]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.78it/s, Epoch=39, Loss=4.25]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.85it/s, Epoch=40, Loss=4.1]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.75it/s, Epoch=41, Loss=4.1]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.84it/s, Epoch=42, Loss=4.35]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.73it/s, Epoch=43, Loss=4.17]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.74it/s, Epoch=44, Loss=4.22]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.77it/s, Epoch=45, Loss=4.36]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.75it/s, Epoch=46, Loss=4.2]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.83it/s, Epoch=47, Loss=4.16]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.74it/s, Epoch=48, Loss=4.25]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.81it/s, Epoch=49, Loss=4.06]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.72it/s, Epoch=50, Loss=3.78]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.74it/s, Epoch=51, Loss=3.93]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.72it/s, Epoch=52, Loss=3.85]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.73it/s, Epoch=53, Loss=4.08]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.77it/s, Epoch=54, Loss=4.11]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.73it/s, Epoch=55, Loss=3.64]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.80it/s, Epoch=56, Loss=3.66]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.72it/s, Epoch=57, Loss=3.93]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.78it/s, Epoch=58, Loss=3.74]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.78it/s, Epoch=59, Loss=3.21]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.75it/s, Epoch=60, Loss=3.54]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.80it/s, Epoch=61, Loss=3.08]\n",
            "100%|██████████| 54/54 [00:07<00:00,  7.67it/s, Epoch=62, Loss=2.77]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.81it/s, Epoch=63, Loss=2.51]\n",
            "100%|██████████| 54/54 [00:07<00:00,  7.70it/s, Epoch=64, Loss=2.34]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.75it/s, Epoch=65, Loss=2.36]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.75it/s, Epoch=66, Loss=2.1]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.72it/s, Epoch=67, Loss=2.06]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.82it/s, Epoch=68, Loss=1.68]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.72it/s, Epoch=69, Loss=1.78]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.81it/s, Epoch=70, Loss=1.4]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.72it/s, Epoch=71, Loss=1.2]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.80it/s, Epoch=72, Loss=1.01]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.81it/s, Epoch=73, Loss=0.97]\n",
            "100%|██████████| 54/54 [00:07<00:00,  7.71it/s, Epoch=74, Loss=0.925]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.81it/s, Epoch=75, Loss=0.847]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.73it/s, Epoch=76, Loss=1.03]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.80it/s, Epoch=77, Loss=0.597]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.73it/s, Epoch=78, Loss=0.683]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.76it/s, Epoch=79, Loss=0.371]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.72it/s, Epoch=80, Loss=0.492]\n",
            "100%|██████████| 54/54 [00:07<00:00,  7.71it/s, Epoch=81, Loss=0.372]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.85it/s, Epoch=82, Loss=0.579]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.73it/s, Epoch=83, Loss=0.287]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.85it/s, Epoch=84, Loss=0.371]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.77it/s, Epoch=85, Loss=0.185]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.80it/s, Epoch=86, Loss=0.148]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.78it/s, Epoch=87, Loss=0.0629]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.76it/s, Epoch=88, Loss=-.0564]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.78it/s, Epoch=89, Loss=0.126]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.75it/s, Epoch=90, Loss=0.408]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.80it/s, Epoch=91, Loss=0.154]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.72it/s, Epoch=92, Loss=0.12]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.84it/s, Epoch=93, Loss=0.0669]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.77it/s, Epoch=94, Loss=0.328]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.78it/s, Epoch=95, Loss=0.306]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.81it/s, Epoch=96, Loss=0.232]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.75it/s, Epoch=97, Loss=0.235]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.85it/s, Epoch=98, Loss=-.0629]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.73it/s, Epoch=99, Loss=-.0809]\n",
            "100%|██████████| 54/54 [00:06<00:00,  7.79it/s, Epoch=100, Loss=0.00485]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last iteration loss value: 0.004853360820561647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}